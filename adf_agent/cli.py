"""
ADF Agent CLI

å‘½ä»¤è¡Œå…¥å£ï¼Œæä¾›äº¤äº’å¼å¯¹è¯åŠŸèƒ½ï¼š
- æµå¼è¾“å‡ºæ”¯æŒ Extended Thinking
- ADF é…ç½®çŠ¶æ€æ˜¾ç¤º
- å·¥å…·è°ƒç”¨å¯è§†åŒ–
"""

import argparse
import json
import os
import shutil
import sys
from pathlib import Path

from dotenv import load_dotenv
from prompt_toolkit import PromptSession
from prompt_toolkit.history import FileHistory
from prompt_toolkit.auto_suggest import AutoSuggestFromHistory
from prompt_toolkit.formatted_text import HTML
from rich.console import Console, Group
from rich.panel import Panel
from rich.markdown import Markdown
from rich.table import Table
from rich.live import Live
from rich.text import Text
from rich.spinner import Spinner

from .agent import ADFAgent, load_adf_config
from .context import _use_workspace, ADFAgentContext
from .stream import (
    ToolResultFormatter,
    has_args,
    DisplayLimits,
    ToolStatus,
    format_tool_compact,
    is_success,
)


# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(override=True)

# Rich Console é…ç½®
console = Console(
    legacy_windows=(sys.platform == 'win32'),
    no_color=os.getenv('NO_COLOR') is not None,
)

# å…¨å±€å·¥å…·ç»“æœæ ¼å¼åŒ–å™¨
formatter = ToolResultFormatter()


# === ç»ˆç«¯é«˜åº¦è®¡ç®— ===

def get_display_heights(con: Console) -> dict:
    """æ ¹æ®ç»ˆç«¯é«˜åº¦è®¡ç®—å„åŒºåŸŸçš„æ˜¾ç¤ºè¡Œæ•°é™åˆ¶"""
    terminal_height = con.height or 25
    available = terminal_height - 5  # é¢„ç•™ç©ºé—´

    return {
        "thinking": max(3, available // 5),
        "tools": max(5, available * 3 // 10),
        "response": max(5, available // 2),
    }


def truncate_to_lines(text: str, max_lines: int) -> str:
    """æˆªæ–­æ–‡æœ¬åˆ°æŒ‡å®šè¡Œæ•°ï¼Œä¿ç•™æœ€æ–°å†…å®¹"""
    lines = text.split('\n')
    if len(lines) <= max_lines:
        return text
    return "...\n" + '\n'.join(lines[-max_lines + 1:])


# === æµå¼å¤„ç†çŠ¶æ€ ===

class StreamState:
    """æµå¼å¤„ç†çŠ¶æ€å®¹å™¨"""

    def __init__(self):
        self.thinking_text = ""
        self.response_text = ""
        self.tool_calls = []
        self.tool_results = []
        self.is_thinking = False
        self.is_responding = False
        self.is_processing = False
        self.token_usage = None  # TokenUsageInfo dict (total)
        self.turn_token_usages = []  # Per-turn token usages (aligned with tool_results)

    def handle_event(self, event: dict) -> str:
        """å¤„ç†å•ä¸ªæµå¼äº‹ä»¶"""
        event_type = event.get("type")

        if event_type == "thinking":
            self.is_thinking = True
            self.is_responding = False
            self.is_processing = False
            self.thinking_text += event.get("content", "")

        elif event_type == "text":
            self.is_thinking = False
            self.is_responding = True
            self.is_processing = False
            self.response_text += event.get("content", "")

        elif event_type == "tool_call":
            self.is_thinking = False
            self.is_responding = False
            self.is_processing = False

            tool_id = event.get("id", "")
            tc_data = {
                "id": tool_id,
                "name": event.get("name", "unknown"),
                "args": event.get("args", {}),
            }

            # ç”¨ tool_id å»é‡å’Œæ›´æ–°
            if tool_id:
                updated = False
                for i, tc in enumerate(self.tool_calls):
                    if tc.get("id") == tool_id:
                        self.tool_calls[i] = tc_data
                        updated = True
                        break
                if not updated:
                    self.tool_calls.append(tc_data)
            else:
                self.tool_calls.append(tc_data)

        elif event_type == "tool_result":
            self.is_processing = True
            self.tool_results.append({
                "name": event.get("name", "unknown"),
                "content": event.get("content", ""),
            })

        elif event_type == "done":
            self.is_processing = False
            if not self.response_text:
                self.response_text = event.get("response", "")

        elif event_type == "token_usage":
            usage = {
                "input_tokens": event.get("input_tokens", 0),
                "output_tokens": event.get("output_tokens", 0),
                "total_tokens": event.get("total_tokens", 0),
                "cache_creation_input_tokens": event.get("cache_creation_input_tokens", 0),
                "cache_read_input_tokens": event.get("cache_read_input_tokens", 0),
            }
            is_total = event.get("is_total", False)
            parallel_count = event.get("parallel_count", 1)
            if is_total:
                # æ±‡æ€»ï¼ˆæ‰€æœ‰ API è°ƒç”¨çš„ SUMï¼‰
                self.token_usage = usage
            else:
                # Per-turn: parallel tools çš„ token æ˜¾ç¤ºåœ¨æœ€åä¸€ä¸ª tool ä¸Š
                if parallel_count > 1:
                    usage["parallel_count"] = parallel_count
                    # ä¸ºå‰é¢çš„ parallel tools å¡«å…… None
                    while len(self.turn_token_usages) < len(self.tool_results) - 1:
                        self.turn_token_usages.append(None)
                if len(self.tool_results) > len(self.turn_token_usages):
                    self.turn_token_usages.append(usage)

        elif event_type == "error":
            self.is_processing = False
            self.is_thinking = False
            self.is_responding = False
            error_msg = event.get("message", "Unknown error")
            self.response_text += f"\n\n[Error] {error_msg}"

        return event_type

    def get_display_args(self) -> dict:
        """è·å–ç”¨äº create_streaming_display çš„å‚æ•°"""
        return {
            "thinking_text": self.thinking_text,
            "response_text": self.response_text,
            "tool_calls": self.tool_calls,
            "tool_results": self.tool_results,
            "turn_token_usages": self.turn_token_usages,
            "is_thinking": self.is_thinking,
            "is_responding": self.is_responding,
            "is_processing": self.is_processing,
        }


def display_token_usage(token_usage: dict) -> None:
    """æ˜¾ç¤º token ä½¿ç”¨é‡"""
    if not token_usage:
        return

    input_tokens = token_usage.get("input_tokens", 0)
    output_tokens = token_usage.get("output_tokens", 0)
    total_tokens = token_usage.get("total_tokens", 0)
    cache_read = token_usage.get("cache_read_input_tokens", 0)
    cache_creation = token_usage.get("cache_creation_input_tokens", 0)

    if total_tokens == 0:
        return

    # æ ¼å¼åŒ–æ•°å­—ï¼Œæ·»åŠ åƒä½åˆ†éš”ç¬¦
    def fmt(n: int) -> str:
        return f"{n:,}"

    # åˆ†éš”çº¿å’Œ token ä¿¡æ¯
    console.print("â”€" * 40, style="dim")

    # Build display string
    base = f"Tokens: {fmt(input_tokens)} input / {fmt(output_tokens)} output | Total: {fmt(total_tokens)}"

    # Add cache info if present
    if cache_read > 0 or cache_creation > 0:
        cache_parts = []
        if cache_read > 0:
            cache_parts.append(f"{fmt(cache_read)} read")
        if cache_creation > 0:
            cache_parts.append(f"{fmt(cache_creation)} write")
        base += f" | Cache: {', '.join(cache_parts)}"

    console.print(f"[dim]{base}[/dim]")


def format_turn_token_usage(token_usage: dict | None) -> Text | None:
    """æ ¼å¼åŒ–å•ä¸ª turn çš„ token ä½¿ç”¨é‡ï¼ˆå†…è”æ˜¾ç¤ºï¼‰"""
    if not token_usage:
        return None

    input_tokens = token_usage.get("input_tokens", 0)
    output_tokens = token_usage.get("output_tokens", 0)
    cache_read = token_usage.get("cache_read_input_tokens", 0)
    cache_creation = token_usage.get("cache_creation_input_tokens", 0)
    parallel_count = token_usage.get("parallel_count", 1)

    if input_tokens == 0 and output_tokens == 0:
        return None

    # æ ¼å¼åŒ–æ•°å­—ï¼Œæ·»åŠ åƒä½åˆ†éš”ç¬¦
    def fmt(n: int) -> str:
        return f"{n:,}"

    # Build display string
    base = f"  â†³ {fmt(input_tokens)} in / {fmt(output_tokens)} out"

    # Parallel indicator
    if parallel_count > 1:
        base += f" (parallel, {parallel_count} tools)"

    # Add cache info if present
    if cache_read > 0 or cache_creation > 0:
        cache_parts = []
        if cache_read > 0:
            cache_parts.append(f"{fmt(cache_read)} read")
        if cache_creation > 0:
            cache_parts.append(f"{fmt(cache_creation)} write")
        base += f" (cache: {', '.join(cache_parts)})"

    return Text(base, style="dim")


def format_tool_result_compact(
    name: str,
    content: str,
    max_lines: int = 5,
    token_usage: dict | None = None,
) -> list:
    """ä½¿ç”¨æ ‘å½¢æ ¼å¼æ˜¾ç¤ºå·¥å…·ç»“æœ"""
    elements = []

    if not content.strip():
        elements.append(Text("  â”” (empty)", style="dim"))
    else:
        lines = content.strip().split("\n")
        total_lines = len(lines)
        display_lines = lines[:max_lines]

        for i, line in enumerate(display_lines):
            prefix = "â””" if i == 0 else " "
            if len(line) > 80:
                line = line[:77] + "..."
            style = "dim" if is_success(content) else "red dim"
            elements.append(Text(f"  {prefix} {line}", style=style))

        remaining = total_lines - max_lines
        if remaining > 0:
            elements.append(Text(f"    ... +{remaining} lines", style="dim italic"))

    # æ·»åŠ  token ä½¿ç”¨é‡æ˜¾ç¤ºï¼ˆåœ¨ç»“æœä¸‹æ–¹ï¼‰
    token_text = format_turn_token_usage(token_usage)
    if token_text:
        elements.append(token_text)

    return elements


def display_final_results(
    state: StreamState,
    thinking_max_length: int = DisplayLimits.THINKING_FINAL,
    tool_result_max_length: int = DisplayLimits.TOOL_RESULT_FINAL,
    show_thinking: bool = True,
    show_tools: bool = True,
    show_response_panel: bool = True,
):
    """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
    # æ˜¾ç¤º thinking
    if show_thinking and state.thinking_text:
        display_thinking = state.thinking_text
        if len(display_thinking) > thinking_max_length:
            half = thinking_max_length // 2
            display_thinking = display_thinking[:half] + "\n\n... (truncated) ...\n\n" + display_thinking[-half:]
        console.print(Panel(
            Text(display_thinking, style="dim"),
            title="Thinking",
            border_style="blue",
        ))

    # æ˜¾ç¤ºå·¥å…·è°ƒç”¨å’Œç»“æœ
    if show_tools and state.tool_calls:
        for i, tc in enumerate(state.tool_calls):
            has_result = i < len(state.tool_results)
            tr = state.tool_results[i] if has_result else None
            content = tr.get('content', '') if tr else ''
            # è·å–è¯¥ turn çš„ token ä½¿ç”¨é‡
            turn_tokens = state.turn_token_usages[i] if i < len(state.turn_token_usages) else None

            if has_result and is_success(content):
                status = ToolStatus.SUCCESS
                style = "bold green"
            elif has_result:
                status = ToolStatus.ERROR
                style = "bold red"
            else:
                status = ToolStatus.PENDING
                style = "dim"

            tool_compact = format_tool_compact(tc['name'], tc.get('args'))
            tool_text = Text()
            tool_text.append(f"{status.value} ", style=style)
            tool_text.append(tool_compact, style=style)
            console.print(tool_text)

            if has_result:
                result_elements = format_tool_result_compact(
                    tr['name'],
                    content,
                    max_lines=10,
                    token_usage=turn_tokens,
                )
                for elem in result_elements:
                    console.print(elem)
        console.print()

    # æ˜¾ç¤ºæœ€ç»ˆå“åº”
    if state.response_text:
        if show_response_panel:
            console.print(Panel(
                Markdown(state.response_text),
                title="Response",
                border_style="green",
            ))
        else:
            console.print(f"\n[bold blue]Assistant:[/bold blue]")
            console.print(Markdown(state.response_text))
            console.print()

    # æ˜¾ç¤º token ä½¿ç”¨é‡
    display_token_usage(state.token_usage)


def create_streaming_display(
    thinking_text: str = "",
    response_text: str = "",
    tool_calls: list = None,
    tool_results: list = None,
    turn_token_usages: list = None,
    is_thinking: bool = False,
    is_responding: bool = False,
    is_waiting: bool = False,
    is_processing: bool = False,
    max_heights: dict = None,
) -> Group:
    """åˆ›å»ºæµå¼æ˜¾ç¤ºçš„å¸ƒå±€"""
    elements = []
    tool_calls = tool_calls or []
    tool_results = tool_results or []
    turn_token_usages = turn_token_usages or []

    if max_heights is None:
        max_heights = {"thinking": 10, "tools": 10, "response": 15}

    # åˆå§‹ç­‰å¾…çŠ¶æ€
    if is_waiting and not thinking_text and not response_text and not tool_calls:
        spinner = Spinner("dots", text=" AI æ­£åœ¨æ€è€ƒä¸­...", style="cyan")
        elements.append(spinner)
        return Group(*elements)

    # Thinking é¢æ¿
    if thinking_text:
        thinking_title = "Thinking"
        if is_thinking:
            thinking_title += " ..."
        display_thinking = truncate_to_lines(thinking_text, max_heights["thinking"])
        thinking_height = min(len(display_thinking.split('\n')), max_heights["thinking"]) + 2
        elements.append(Panel(
            Text(display_thinking, style="dim"),
            title=thinking_title,
            border_style="blue",
            padding=(0, 1),
            height=thinking_height,
        ))

    # Tool Calls æ˜¾ç¤º
    if tool_calls:
        tools_max_lines = max_heights["tools"]
        lines_per_tool = max(2, tools_max_lines // max(1, len(tool_calls)))

        for i, tc in enumerate(tool_calls):
            has_result = i < len(tool_results)
            tr = tool_results[i] if has_result else None
            # è·å–è¯¥ turn çš„ token ä½¿ç”¨é‡
            turn_tokens = turn_token_usages[i] if i < len(turn_token_usages) else None

            if has_result:
                content = tr.get('content', '') if tr else ''
                if is_success(content):
                    status = ToolStatus.SUCCESS
                    style = "bold green"
                else:
                    status = ToolStatus.ERROR
                    style = "bold red"
            else:
                status = ToolStatus.RUNNING
                style = "bold yellow"

            tool_compact = format_tool_compact(tc['name'], tc.get('args'))
            tool_text = Text()
            tool_text.append(f"{status.value} ", style=style)
            tool_text.append(tool_compact, style=style)
            elements.append(tool_text)

            if has_result:
                result_elements = format_tool_result_compact(
                    tr['name'],
                    tr.get('content', ''),
                    max_lines=lines_per_tool,
                    token_usage=turn_tokens,
                )
                elements.extend(result_elements[:lines_per_tool + 1])  # +1 for token line
            else:
                spinner = Spinner("dots", text=" æ‰§è¡Œä¸­...", style="yellow")
                elements.append(spinner)

    # å·¥å…·æ‰§è¡Œåç­‰å¾…
    if is_processing and not is_thinking and not is_responding and not response_text:
        spinner = Spinner("dots", text=" AI æ­£åœ¨åˆ†æç»“æœ...", style="cyan")
        elements.append(spinner)

    # Response é¢æ¿
    if response_text:
        response_title = "Response"
        if is_responding:
            response_title += " ..."
        display_response = truncate_to_lines(response_text, max_heights["response"])
        response_height = min(len(display_response.split('\n')), max_heights["response"]) + 2
        elements.append(Panel(
            Markdown(display_response),
            title=response_title,
            border_style="green",
            padding=(0, 1),
            height=response_height,
        ))
    elif is_responding and not thinking_text:
        elements.append(Text("â³ Generating response...", style="dim"))

    return Group(*elements) if elements else Text("â³ Processing...", style="dim")


# === Onboarding ===

def _needs_onboarding() -> bool:
    """æ£€æŸ¥æ˜¯å¦éœ€è¦ onboardingï¼ˆæ²¡æœ‰ä»»ä½• API å‡­è¯ï¼‰"""
    has_anthropic = bool(
        os.getenv("ANTHROPIC_API_KEY") or os.getenv("ANTHROPIC_AUTH_TOKEN")
    )
    has_foundry = bool(os.getenv("ANTHROPIC_FOUNDRY_API_KEY"))
    return not has_anthropic and not has_foundry


def _read_key() -> str | None:
    """è¯»å–å•ä¸ªæŒ‰é”®ï¼Œå¤„ç†æ–¹å‘é”®è½¬ä¹‰åºåˆ—"""
    import tty, termios

    fd = sys.stdin.fileno()
    old = termios.tcgetattr(fd)
    try:
        tty.setraw(fd)
        ch = sys.stdin.read(1)
        if ch == '\x1b':
            sys.stdin.read(1)  # skip '['
            arrow = sys.stdin.read(1)
            return {'A': 'up', 'B': 'down'}.get(arrow)
        if ch in ('\r', '\n'):
            return 'enter'
        if ch == '\x03':
            raise KeyboardInterrupt
    finally:
        termios.tcsetattr(fd, termios.TCSADRAIN, old)
    return None


def _select(title: str, options: list[tuple[str, str]], default: int = 0) -> str | None:
    """
    Arrow-key inline selector.

    Args:
        title: æ ‡é¢˜
        options: [(value, label), ...]
        default: é»˜è®¤é€‰ä¸­ç´¢å¼•

    Returns:
        é€‰ä¸­çš„ valueï¼ŒCtrl+C è¿”å› None
    """
    selected = default
    n = len(options)
    first = True

    def render():
        nonlocal first
        if not first:
            sys.stdout.write(f"\033[{n}A")  # move cursor up
        first = False
        for i, (_, label) in enumerate(options):
            sys.stdout.write('\033[2K')  # clear line
            if i == selected:
                sys.stdout.write(f"    \033[36mâ–¸ {label}\033[0m\n")
            else:
                sys.stdout.write(f"      {label}\n")
        sys.stdout.flush()

    console.print(f"  [bold]{title}[/bold] [dim](â†‘â†“ select, Enter confirm)[/dim]")
    render()

    try:
        while True:
            key = _read_key()
            if key == 'up':
                selected = (selected - 1) % n
                render()
            elif key == 'down':
                selected = (selected + 1) % n
                render()
            elif key == 'enter':
                return options[selected][0]
    except KeyboardInterrupt:
        console.print()
        return None


def _update_env_file(env_path: Path, updates: dict[str, str]):
    """æ›´æ–° .env æ–‡ä»¶ä¸­çš„ key=valueï¼Œå¤„ç†é‡å¤ key"""
    content = env_path.read_text(encoding="utf-8")
    lines = content.splitlines()
    updated_keys = set()
    new_lines = []

    for line in lines:
        stripped = line.strip()

        if not stripped or stripped.startswith('#'):
            new_lines.append(line)
            continue

        key = stripped.split('=', 1)[0].strip()

        if key in updates and key not in updated_keys:
            new_lines.append(f"{key}={updates[key]}")
            updated_keys.add(key)
        elif key in updates:
            # é‡å¤çš„ keyï¼Œæ³¨é‡Šæ‰
            new_lines.append(f"# {line}")
        else:
            new_lines.append(line)

    # è¿½åŠ æ–‡ä»¶ä¸­ä¸å­˜åœ¨çš„ key
    for key, value in updates.items():
        if key not in updated_keys:
            new_lines.append(f"{key}={value}")

    env_path.write_text('\n'.join(new_lines) + '\n', encoding='utf-8')


def run_onboarding() -> bool:
    """
    äº¤äº’å¼ onboardingï¼šå¼•å¯¼ç”¨æˆ·é…ç½® API å‡­è¯ã€‚

    Returns:
        True å¦‚æœé…ç½®æˆåŠŸå®Œæˆ
    """
    console.print()
    console.print(Panel(
        "[bold]Welcome to ADF Agent![/bold]\n\n"
        "No API credentials detected. Let's set up your environment.",
        border_style="cyan",
    ))
    console.print()

    # Step 1: Provider
    provider = _select("API Provider", [
        ("anthropic", "Claude API (Anthropic)"),
        ("azure_foundry", "Claude API on Azure AI Foundry"),
    ])
    if provider is None:
        return False

    is_foundry = provider == "azure_foundry"
    console.print()

    # Step 2: Model
    model = _select("Model", [
        ("claude-sonnet-4-5", "claude-sonnet-4-5 (recommended)"),
        ("claude-opus-4-5", "claude-opus-4-5"),
        ("claude-haiku-4-5", "claude-haiku-4-5"),
    ])
    if model is None:
        return False

    console.print()

    # Step 3: API Key
    console.print("  [bold]API Key[/bold]")
    if is_foundry:
        api_key = input("    Azure Foundry API Key: ").strip()
    else:
        api_key = input("    Anthropic API Key: ").strip()

    if not api_key:
        console.print("  [red]API key is required.[/red]")
        return False

    # Step 4: Base URL (Foundry only)
    base_url = ""
    if is_foundry:
        console.print()
        console.print("  [bold]Azure Foundry Base URL[/bold]")
        console.print("    [dim]e.g. https://<resource>.services.ai.azure.com/anthropic[/dim]")
        base_url = input("    Base URL: ").strip()
        if not base_url:
            console.print("  [red]Base URL is required for Azure Foundry.[/red]")
            return False

    # --- å†™å…¥ .env ---
    env_file = Path.cwd() / ".env"
    env_example = Path.cwd() / ".env.example"

    if not env_file.exists() and env_example.exists():
        shutil.copy2(env_example, env_file)
    elif not env_file.exists():
        env_file.touch()

    updates = {"CLAUDE_MODEL": model}
    if is_foundry:
        updates["CLAUDE_PROVIDER"] = "azure_foundry"
        updates["ANTHROPIC_FOUNDRY_API_KEY"] = api_key
        updates["ANTHROPIC_FOUNDRY_BASE_URL"] = base_url
    else:
        updates["CLAUDE_PROVIDER"] = "anthropic"
        updates["ANTHROPIC_AUTH_TOKEN"] = api_key

    _update_env_file(env_file, updates)

    # å®Œæˆæç¤º
    provider_label = "Azure AI Foundry" if is_foundry else "Anthropic"
    console.print()
    console.print(Panel(
        f"[green]Configuration saved to .env[/green]\n\n"
        f"  Provider: [bold]{provider_label}[/bold]\n"
        f"  Model:    [bold]{model}[/bold]\n\n"
        f"Run [bold cyan]adf_agent[/bold cyan] again to start.",
        border_style="green",
        title="Setup Complete",
    ))

    return True


def print_banner():
    """æ‰“å°æ¬¢è¿æ¨ªå¹…"""
    banner = """
[bold cyan]ADF Agent[/bold cyan]
[dim]Azure Data Factory åŠ©æ‰‹[/dim]

å¸®åŠ©ä½ æ¢ç´¢å’Œç®¡ç† Azure Data Factory èµ„æºï¼š
- åˆ—å‡ºå’Œåˆ†æ Pipelinesã€Linked Servicesã€Integration Runtimes
- æµ‹è¯•è¿æ¥ã€å¯ç”¨ Interactive Authoring
- ä½¿ç”¨ Python åˆ†æ JSON æ•°æ®
"""
    console.print(Panel(banner, title="ADF Agent", border_style="cyan"))


def show_config_status(agent: ADFAgent = None):
    """æ˜¾ç¤ºé…ç½®çŠ¶æ€

    Args:
        agent: å¯é€‰ï¼Œå¦‚æœæä¾›åˆ™æ˜¾ç¤ºå®é™…çš„ session_dir
    """
    config = load_adf_config()

    if config.is_configured():
        console.print(f"[green]âœ“[/green] ADF: {config.factory_name} (RG: {config.resource_group})")
    else:
        missing = config.missing_fields()
        console.print(f"[yellow]![/yellow] ADF config incomplete - missing: {', '.join(missing)}")
        console.print("[dim]  Agent will ask when ADF operations are needed[/dim]")

    # æ˜¾ç¤ºå­˜å‚¨ä½ç½®ï¼ˆä»…å½“ä½¿ç”¨ temp ç›®å½•æ—¶ï¼‰
    if not _use_workspace():
        if agent:
            # ä½¿ç”¨ Agent çš„å®é™… session_dir
            console.print(f"[dim]ğŸ“ Session dir: {agent.context.session_dir}[/dim]")
        else:
            # åªæ˜¾ç¤º base è·¯å¾„
            import tempfile
            base_path = Path(tempfile.gettempdir()) / "adf_agent" / "sessions"
            console.print(f"[dim]ğŸ“ Output dir: {base_path}/[/dim]")


def cmd_run(prompt: str, enable_thinking: bool = True):
    """æ‰§è¡Œå•æ¬¡è¯·æ±‚"""
    console.print(Panel(f"[bold cyan]User Request:[/bold cyan]\n{prompt}"))
    console.print()

    agent = ADFAgent(enable_thinking=enable_thinking)

    console.print("[dim]Running agent...[/dim]\n")

    try:
        state = StreamState()

        with Live(console=console, refresh_per_second=10, transient=True) as live:
            live.update(create_streaming_display(is_waiting=True))

            for event in agent.stream_events(prompt):
                event_type = state.handle_event(event)
                heights = get_display_heights(console)
                live.update(create_streaming_display(
                    **state.get_display_args(),
                    max_heights=heights,
                ))

                if event_type in ("tool_call", "tool_result"):
                    live.refresh()

        console.print()
        display_final_results(
            state,
            tool_result_max_length=1000,
            show_response_panel=True,
        )

    except Exception as e:
        console.print(f"[red]Error: {e}[/red]")
        raise


def cmd_interactive(enable_thinking: bool = True):
    """äº¤äº’å¼å¯¹è¯æ¨¡å¼"""
    print_banner()

    agent = ADFAgent(enable_thinking=enable_thinking)

    # æ˜¾ç¤ºé…ç½®çŠ¶æ€ï¼ˆä¼ å…¥ agent ä»¥æ˜¾ç¤ºå®é™…çš„ session_dirï¼‰
    show_config_status(agent)
    console.print()

    thinking_status = "[green]enabled[/green]" if enable_thinking else "[dim]disabled[/dim]"
    console.print(f"[dim]Extended Thinking: {thinking_status}[/dim]")
    console.print("[dim]Commands: /exit to quit, /help for examples[/dim]\n")

    thread_id = "interactive"

    # åˆå§‹åŒ– prompt_toolkit session
    history_file = str(Path.home() / ".adf_agent_history")
    session = PromptSession(
        history=FileHistory(history_file),
        auto_suggest=AutoSuggestFromHistory(),
        enable_history_search=True,
    )

    while True:
        try:
            user_input = session.prompt(
                HTML('<ansigreen><b>You:</b></ansigreen> ')
            ).strip()

            if not user_input:
                continue

            # ç‰¹æ®Šå‘½ä»¤
            if user_input.lower() in ("/exit", "/quit", "/q"):
                console.print("[dim]Goodbye![/dim]")
                break

            if user_input.lower() == "/help":
                show_help()
                continue

            if user_input.lower() == "/config":
                show_config_status(agent)
                continue

            # è¿è¡Œ agent
            console.print()

            state = StreamState()

            with Live(console=console, refresh_per_second=10, transient=True) as live:
                live.update(create_streaming_display(is_waiting=True))

                for event in agent.stream_events(user_input, thread_id=thread_id):
                    event_type = state.handle_event(event)
                    heights = get_display_heights(console)
                    live.update(create_streaming_display(
                        **state.get_display_args(),
                        max_heights=heights,
                    ))

                    if event_type in ("tool_call", "tool_result"):
                        live.refresh()

            # æ˜¾ç¤ºæœ€ç»ˆç»“æœï¼ˆäº¤äº’æ¨¡å¼ç®€åŒ–æ˜¾ç¤ºï¼‰
            display_final_results(
                state,
                thinking_max_length=500,
                tool_result_max_length=DisplayLimits.TOOL_RESULT_FINAL,
                show_thinking=True,
                show_tools=True,
                show_response_panel=True,
            )
            console.print()  # ä¸ä¸‹ä¸€ä¸ªè¾“å…¥æç¤ºä¿æŒè·ç¦»

        except KeyboardInterrupt:
            console.print("\n[dim]Goodbye![/dim]")
            break
        except Exception as e:
            console.print(f"[red]Error: {e}[/red]")


def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    help_text = """
## Example Queries

**List resources:**
- åˆ—å‡ºæ‰€æœ‰ pipeline
- åˆ—å‡ºæ‰€æœ‰ linked service
- åˆ—å‡º Snowflake ç±»å‹çš„ linked service

**Find relationships:**
- å“ªäº› pipeline ä½¿ç”¨äº† Snowflake linked service?
- åˆ†æ linked service ç±»å‹åˆ†å¸ƒ

**Test connections:**
- æµ‹è¯• linked service "my-snowflake" çš„è¿æ¥
- å¯ç”¨ Integration Runtime "ir-managed" çš„ interactive authoring

**Analyze data:**
- åˆ†æ workspace/pipelines.json ä¸­çš„æ•°æ®
- ç»Ÿè®¡æ¯ä¸ª pipeline çš„ activity æ•°é‡

## Commands

- `/exit` - Exit the agent
- `/help` - Show this help
- `/config` - Show ADF configuration status
"""
    console.print(Markdown(help_text))


def main():
    """CLI ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="ADF Agent - Azure Data Factory åŠ©æ‰‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # äº¤äº’å¼æ¨¡å¼
  %(prog)s --interactive

  # æ‰§è¡Œå•æ¬¡è¯·æ±‚
  %(prog)s "åˆ—å‡ºæ‰€æœ‰ pipeline"

  # ç¦ç”¨ thinking
  %(prog)s --no-thinking "åˆ—å‡ºæ‰€æœ‰ linked service"
""",
    )

    parser.add_argument(
        "prompt",
        nargs="?",
        help="è¦æ‰§è¡Œçš„è¯·æ±‚",
    )
    parser.add_argument(
        "-i", "--interactive",
        action="store_true",
        help="è¿›å…¥äº¤äº’å¼å¯¹è¯æ¨¡å¼",
    )
    parser.add_argument(
        "--no-thinking",
        action="store_true",
        help="ç¦ç”¨ Extended Thinking",
    )
    parser.add_argument(
        "--cwd",
        type=str,
        help="è®¾ç½®å·¥ä½œç›®å½•",
    )

    args = parser.parse_args()

    # è®¾ç½®å·¥ä½œç›®å½•
    if args.cwd:
        os.chdir(args.cwd)

    # Onboarding: æ£€æŸ¥ API å‡­è¯ï¼Œç¼ºå¤±æ—¶å¼•å¯¼é…ç½®
    if _needs_onboarding():
        run_onboarding()
        sys.exit(0)

    # thinking å¼€å…³
    enable_thinking = not args.no_thinking

    # æ‰§è¡Œå‘½ä»¤
    if args.interactive:
        cmd_interactive(enable_thinking=enable_thinking)
    elif args.prompt:
        cmd_run(args.prompt, enable_thinking=enable_thinking)
    else:
        # é»˜è®¤è¿›å…¥äº¤äº’æ¨¡å¼
        cmd_interactive(enable_thinking=enable_thinking)


if __name__ == "__main__":
    main()
